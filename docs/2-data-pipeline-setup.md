# Data Pipeline Setup

## Overview

The data pipeline consists of 5 steps.

### 1. Data loading

This serves as the entry point of the process, which initialises the data pipeline and calls the relevant functions to carry out the rest of the steps.

### 2. Tiling

This subprocess ingests the raw images and annotations, performs image tiling and generates the new COCO annotations based on the tiled images. Option to exclude images are executed here.

### 3. Preprocessing

This subprocess combines the annotations generated in the previous steps, cleans the data, performs feature engineering and converts the preprocessed annotations data into CSV format.

### 4. Data splitting

This subprocess stratifies the data according to the configuration and splits it into three sets for training, validation and testing.

### 5. Model-specific preprocessing

This subprocess converts the annotations generated in the previous step into a format that can be ingested by the model (EfficientDet).

## Configuration

The main configuration file used to customise the AI engine is `pipelines.yml`, located in `conf/life3` subfolder.

In `pipelines.yml`, the following parameters in the `data_prep` section are configurable.

| Constant (`const.`) | Parameter | Type | Description | Default Value |
|---|---|---|---|---|
| MODELS | models | list of str | List of model names to run the data loader on. Each model usually requires annotations to be in a particular format for ingestion. | `["efficientdet"]`|
| RAW_DATA_PATH | raw_data_path | str | Absolute path pointing to the raw data directory of the project. This directory should contain the raw data exported from CVAT, to be processed by AI engine, e.g. annotations JSON files and images | |
| INTERIM_DATA_PATH | interim_data_path | str | Absolute path pointing to the interim data directory of the project. This directory is used to store the annotations files generated by the image tiling and preprocessing steps. | |
| PROCESSED_DATA_PATH | processed_data_path | str | Absolute path pointing to the processed data directory of the project. This directory is used to store the final split datasets (train, validation & test) generated. It may also be used to store augmented training images for experimental purpose (see documentation on training pipeline). | |
| ANNOTATIONS_SUBDIR | annotations_subdir | str | Name of subdirectory containing annotation files, residing within the directories listed in `data_subdirs_paths`| "annotations" |
| IMAGES_SUBDIR | images_subdir | str | Name of subdirectory containing image files, residing within the directories listed in `data_subdirs_paths`| "images" |
| COCO_ANNOTATION_FILENAME | coco_annotations_filename | str | Name of JSON file containing annotations, residing within the subdirectory specified in `annotations_subdir`| "instances_default.json" |
| COMBINED_ANNOTATIONS_FILENAME | combined_annotations_filename | str | Name of CSV file containing preprocessed annotations generated into the directory specified in `interim_data_path`| "annotations_all.csv" |
| EXCLUDED_IMAGES | excluded_images | list of str | List of image filenames (str) to exclude from the data pipeline | |
| CLASS_MAP | class_map | dict | Object mapping of the classes and their numerical representations | 
`{'cell': 0, 'cell accumulation': 1}`|
| REMAP_CLASSES | remap_classes | dict | Determines whether remapping of classes is carried out in the preprocessing step. Remapping may be used to combine/collapse two or more class labels into one, or to incorrectly labelled data. | `True`|
| CLASS_REMAPPING | class_remapping | dict | Object mapping of the labelled category names to their corrected labels | |
| ACCEPTED_IMAGE_FORMATS | accepted_image_formats | list of str | A list of image extensions determining the expected image formats for the data (see [here](https://docs.opencv.org/4.5.3/d4/da8/group__imgcodecs.html#ga288b8b3da0892bd651fce07b3bbd3a56) for extensions supported by OpenCV)| `['jpg', 'JPG', 'jpeg', 'png']` |
| **_Tile/Slice_** | | | | |
| RUN_TILING | run_tiling | boolean | Determines whether to tile image at the start of the training process. | `True` |
| TILE_COCO_FILTER_CATEGORIES | tile_coco_filter_categories | list of str | Categories can be filter/selected here for COCO json | - "Cells"<br>- "cell accumulation (small cells)"<br>- "cell accumulation (large cells)" |
| TILE_DATA_DIR_PATHS | tile_data_dir_paths | str | Absolute path pointing to the tile process data directory of the project. This directory contain the same directory structure as original data, with images and coco json processed as tile format. | |
| TILE_SLICE_HEIGHT | tile_slice_height | int | Parameter to determine the height of each tile/slice image. | 512 |
| TILE_SLICE_WIDTH | tile_slice_width | int | Parameter to determine the width of each tile/slice image. | 512 |
| TILE_OVERLAP_HEIGHT_RATIO | tile_overlap_height_ratio | float | Parameter to specify adjacent tiles height overlapping percentage. | 0.2 |
| TILE_OVERLAP_WIDTH_RATIO | tile_overlap_width_ratio | float | Parameter to specify adjacent tiles width overlapping percentage. | 0.2 |
| TILE_IGNORE_NEGATIVE_SAMPLES | tile_ignore_negative_samples | boolean | Determines whether to include images without annotation. Setting as `False` will include images without annotations. | `False` |
| **_Data Split_** |  |  |  |  |
| TARGET_COL | target_col | str | Column name to take reference for the class name | 'category_name' |
| SAVE_DATA_SPLITS | save_data_splits | boolean | Determines whether to save the train/validation/test splits as separate csv files | `True` |
| VAL_SIZE | val_size | float | Proportion of data allocated to the validation set, based on the proportion of the overall data | 0.1 |
| TEST_SIZE | test_size | float | Proportion of data allocated to the test set, based on the proportion of the overall data | 0.2 |
| TRAIN_BASE_FILENAME | train_base_filename | str | Base filename (prefix) to be used for naming the train split file | 'train.csv' |
| VAL_BASE_FILENAME | validation_base_filename | str | Base filename (prefix) to be used for naming the validation split file | 'validation.csv' |
| TEST_BASE_FILENAME | test_base_filename | str | Base filename (prefix) to be used for naming the test split file | 'test.csv' |
| META_DATA_FILENAME | meta_data_filename | str | Meta data that contain extra information of the images such as incubation_day filepath and filename. | |
| STRATIFY_COLUMN | stratify_column | str | Column name that will be used for data stratification. | 'incubation_day' |

## Running the data pipeline

To run the data pipeline only (without entering the model training pipeline), open Anaconda Prompt and run the following commands:

```
cd C:\ai_engine
conda activate life3-biotech
python -m src.load_data
```

Upon successful run of the pipeline, the following message would be printed in the console log: `Data preparation pipeline has completed.`

Additionally, the following files would be generated in the `data` directory:

| Files | Location |
|---|---|
| Tiled images and COCO annotations | `tile_data_dir_paths` |
| Tiled images | `raw_data_path` |
 CSV file containing combined & preprocessed annotations, e.g. `annotations_all.csv` | `interim_data_path` |
| CSV file containing train set annotations, e.g. `annotations_train.csv` | `interim_data_path` |
| CSV file containing validation set annotations, e.g. `annotations_val.csv` | `interim_data_path` |
| CSV file containing test set annotations, e.g. `annotations_test.csv` | `interim_data_path` |
| CSV files containing annotations in points 3 to 5, formatted for the EfficientDet model architecture, e.g. `annotations_train_efficientdet_b0.csv`, `annotations_val_efficientdet_b0.csv` and `annotations_test_efficientdet_b0.csv` | `processed_data_path` |
