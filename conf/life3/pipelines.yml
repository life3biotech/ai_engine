data_prep:
  models: [
    "efficientdet"
    ]
  data_subdirs_paths:
    - "C:\\ai_engine\\data\\uploaded\\images 1-7 revised"
    - "C:\\ai_engine\\data\\uploaded\\images 8-24 revised"
    - "C:\\ai_engine\\data\\uploaded\\images 25-35 revised"
    - "C:\\ai_engine\\data\\uploaded\\images 36-55 revised"
    - "C:\\ai_engine\\data\\uploaded\\images 56-75 revised"
    - "C:\\ai_engine\\data\\uploaded\\images 76-100 revised"
  raw_data_path: "C:\\ai_engine\\data\\raw"
  processed_data_path: "C:\\ai_engine\\data\\processed"
  interim_data_path: "C:\\ai_engine\\data\\interim"
  annotations_subdir: "annotations"
  images_subdir: "images"
  coco_annotations_filename: "instances_default.json"
  combined_annotations_filename: "annotations_all.csv"
  excluded_images:
    - "1 c0.7L d5 20x undilut OD15.jpg"
    - "3 c10L d10 20x undilut OD8.jpg"
  class_map: {
        'cell': 0,
        # 'cell accumulation': 1
    }
  remap_classes: True
  class_remapping: {
    'Cells': 'cell',
    'cell accumulation (small cells)': 'cell accumulation',
    'cell accumulation (large cells)': 'cell accumulation'
    }
  accepted_image_formats: ['jpg', 'JPG', 'jpeg', 'png']
  # Tile/slice processed images
  run_tiling: True
  tile_coco_filter_categories:
    - "Cells"
    - "cell accumulation (small cells)"
    - "cell accumulation (large cells)"
  tile_data_dir_paths: "C:\\ai_engine\\data\\processed\\tiled_384"
  tile_slice_height: 384
  tile_slice_width: 384
  tile_overlap_height_ratio: 0.1
  tile_overlap_width_ratio: 0.1
  tile_ignore_negative_samples: False # If True, images without annotations are ignored
  # Data Split
  target_col: 'category_name'
  save_data_splits: True
  val_size: 0.1 # The proportion of data allocated to the validation set, based ongit  the proportion of the overall data
  test_size: 0.2  # The proportion of data allocated to the test set, based on the proportion of the overall data
  train_base_filename: 'annotations_train.csv'
  validation_base_filename: 'annotations_val.csv'
  test_base_filename: 'annotations_test.csv'
  meta_data_filename: "C:\\ai_engine\\data\\metadata.xlsx"
  stratify_column: 'incubation_day' # option: 'incubation_day' or 'dilution_factor' or 'incub_day_dilu_fact' or None. Note: 'incub_day_dilu_fact' not suitable without tiling

train:
  load_data: False
  model_name: "efficientdet"
  save_weights_only: True
  lr_scheduler: "reduce_on_plateau"
  initial_lr: 0.001
  # LR parameters for reduce on plateau
  lr_reduce_factor: 0.1
  lr_reduce_patience: 2
  lr_min_delta: 0.001
  early_stopping: True
  patience: 10
  # Evaluation params
  eval_batch_size: 4
  eval_iou_threshold: [0.5]
  eval_score_threshold: 0.01
  eval_cell_accu_as_cell: False

inference:
  # ===Defined cell size===
  um_pixel_mapping: 0.369763541667  #micrometer/pixel   # Map one pixel of images to the corresponding micrometer for cell size.
  # small-> value 1 ->mid-> value 2 ->large
  small_mid_cell_cutoff: 4.0  # value 1 in micrometer
  mid_large_cell_cutoff: 8.0  # value 2 in micrometer
  use_calibrated_cellsize: True # Used calibrated value for small_mid_cell_cutoff and mid_large_cell_cutoff if True
  # ===Input/Output===
  model_path: "C:\\ai_engine\\models\\efficientdet_b0_20220607_111240.h5"
  image_input_dir: "C:\\ai_engine\\data\\inference\\input"
  csv_output_dir: "C:\\ai_engine\\data\\inference\\output\\csv"
  save_output_image: True # option: True or False
  save_output_image_showlabel: False # Save image with per cell prediction text label. option: True or False
  save_output_image_show_cellcount: True # Save image with total cell count text label. option: True or False
  image_output_dir: "C:\\ai_engine\\data\\inference\\output\\img"
  # ===Model parameter===
  inference_backbone: 0
  confidence_threshold: 0.1
  run_nms: False
  nms_threshold: 0.2
  efficientdet_config: {  # Do not change the default value
      "model_type": 0,
      "detect_ids": [0,1],
  }
  pkd_base_dir: ".\\src\\inferencing\\custom_nodes"  # Do not change the default value
  # ===Postprocessing parameter===
  slice_height: 256  # The height of the image to be sliced (Suggestion: 256, 384, 512)
  # 384 - Balance, good at detecting big and small object. 256, very good at small object but might miss big object. 512, very good at big object but might miss small object
  slice_width: 256 # The width of the image to be sliced (Suggestion: 256, 384, 512)
  # 384 - Balance, good at detecting big and small object. 256, very good at small object but might miss big object. 512, very good at big object but might miss small object
  overlap_height_ratio: 0.15 # Fractional overlap in height of each window (e.g. an overlap of 0.2 for a window of size 512 yields an overlap of 102 pixels).
  overlap_width_ratio: 0.15 # Fractional overlap in width of each window (e.g. an overlap of 0.2 for a window of size 512 yields an overlap of 102 pixels).
  # postprocess_type: Type of the postprocess to be used after sliced inference while merging/eliminating predictions.
  # Options are 'NMM', 'GREEDYNMM' or 'NMS'. Default is 'GREEDYNMM'.
  postprocess_type: 'NMS' 
  postprocess_bbox_sort: True # If True, sort bounding box according to area (Prioritise tighter bounding box). False sort bounding box acccording to score.
  # postprocess_match_metric: Metric to be used during object prediction matching after sliced prediction.
  # 'IOU' for intersection over union, 'IOS' for intersection over smaller area.
  postprocess_match_metric: "IOS"  
  postprocess_match_threshold: 0.01  # Sliced predictions having higher iou than postprocess_match_threshold will be postprocessed after sliced prediction.
  inference_slice: True

efficientdet:
    train_annotations_path: "C:\\ai_engine\\data\\processed\\annotations_train_efficientdet_b0.csv"
    val_annotations_path: "C:\\ai_engine\\data\\processed\\annotations_val_efficientdet_b0.csv"
    test_annotations_path: "C:\\ai_engine\\data\\processed\\annotations_test_efficientdet_b0.csv"
    saved_best_model: '' # model file must exist in directory referenced in snapshot-path below
    snapshot-path: "C:\\ai_engine\\models\\"
    gpu: 0
    train_backbone: 0
    snapshot: 'imagenet'
    compute_val_loss: True
    weighted_bifpn: True
    freeze_bn: False
    freeze_backbone: False
    random_transform: False
    batch_size: 4
    epochs: 100
    steps: 128
    # parameters for anchor boxes
    anchor_box_scales: [0.4, 0.496, 0.625]
    anchor_box_ratios: [1, 0.5, 2]
    # anchor_box_scales: [0.5, 1.0, 2.0]
    image_sizes: [512, 640, 768, 896, 1024, 1280, 1408]
    max_detections: 400
    class_specific_filter: False 
    detect_quadrangle: False 
    score_threshold: 0.9
    select_top_k: False 
